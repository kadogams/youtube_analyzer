{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A class to make a sentiment and emotion analysis on Youtube comments.\n",
    "The analysis are saved locally in an SQLite database.\n",
    "Database schema available at 'data/sqlite_schema/sqlite_diagram.png'\n",
    "\n",
    "requirements:\n",
    " - google-api-python-client\n",
    " - ibm-watson\n",
    " - langdetect\n",
    " - pandas\n",
    "\n",
    "API keys required for the following methods:\n",
    " - self.search(): Google API\n",
    " - self.run_analysis(): Microsoft Azure Text Analytics API\n",
    "                        IBM Watson Natural Language Understanding API\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from langdetect import detect\n",
    "import pandas as pd\n",
    "\n",
    "# from googleapiclient.discovery import build\n",
    "# from google.cloud import translate\n",
    "\n",
    "from sqlite3_wrapper.database import Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite\n",
    "CONFLIT_RESOLUTION_ALGORITHMS = ['ROLLBACK', 'ABORT', 'FAIL', 'IGNORE', 'REPLACE']\n",
    "\n",
    "# Google API Client\n",
    "MAX_SEARCH = 50\n",
    "MAX_COMMENT_THREADS = 100\n",
    "RESULT_ORDERS = ['date', 'rating', 'relevance', 'title', 'videoCount', 'viewCount']\n",
    "COMMENT_ORDERS = ['time', 'relevance']\n",
    "\n",
    "# MS Azure (supported languages for both sentiment analysis and key phrases extraction)\n",
    "AZURE_SUPPORTED_LANG = ['da', 'nl', 'en', 'fi', 'fr', 'de', 'it', 'no', 'pl', 'pt', 'ru', 'es', 'sv']\n",
    "\n",
    "# IBM Watson (supported languages for emotion analysis)\n",
    "WATSON_SUPPORTED_LANG = ['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class youtubeAnalyzer(Database):\n",
    "    \"\"\" A class to manage the YouTube SQLite database.\n",
    "    Inherits from base class 'Database' in database.py (a wrapper around the sqlite3 python library)\n",
    "    Database schema available at 'data/sqlite_schema/sqlite_diagram.png'\n",
    "    \"\"\"\n",
    "\n",
    "    #################\n",
    "    # Magic Methods #\n",
    "    #################\n",
    "\n",
    "    def __init__(self, googleApiKey=None, azureApiKey=None, watsonApiKey=None,\n",
    "                 azureBaseUrl='https://westcentralus.api.cognitive.microsoft.com/text/analytics/v2.1/',\n",
    "                 watsonBaseUrl='https://gateway-lon.watsonplatform.net/natural-language-understanding/api',\n",
    "                 conflict_resolution='IGNORE', sqlite_file='youtube.sqlite'):\n",
    "        \"\"\"\n",
    "        :param str googleApiKey: Developper key for Google API\n",
    "        :param str azureApiKey: Subscription key for Azure Text Analytics API\n",
    "        :param str watsonApiKey: API key for IBM Watson's Natural Language Understanding API\n",
    "        :param str jiveBaseUrl: WAP url\n",
    "        :param str azureBaseUrl: Base url for Azure Text Analytics API\n",
    "        :param str watsonBaseUrl_nlu: Base url for IBM Watson's Natural Language Understanding API\n",
    "        :param str conflict_resolution: ON CONFLICT clause for the SQLite queries. Warning: 'REPLACE' will delete the all Azure and Watson analysis.\n",
    "        :param str sqlite_file: SQLite file name\n",
    "        \"\"\"\n",
    "        if conflict_resolution not in CONFLIT_RESOLUTION_ALGORITHMS:\n",
    "            raise ValueError(\"Valid values for the `conflict_resolution` param are '{}', \"\n",
    "                             \"the given value is invalid: '{}'\"\n",
    "                             .format(\"', '\".join(CONFLIT_RESOLUTION_ALGORITHMS), conflict_resolution))\n",
    "\n",
    "#         path = os.path.dirname(os.path.abspath(__file__)) + '/data'\n",
    "        path = os.getcwd() + '/data'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        self.dir = path + '/' + sqlite_file\n",
    "        self.conn = None\n",
    "        self.cursor = None\n",
    "        self.conflict_resolution = conflict_resolution\n",
    "        \n",
    "        self.googleApiKey = googleApiKey\n",
    "        self.azureApiKey = azureApiKey\n",
    "        self.azureBaseUrl = azureBaseUrl\n",
    "        self.watsonApiKey = watsonApiKey\n",
    "        self.watsonBaseUrl = watsonBaseUrl\n",
    "\n",
    "        try:\n",
    "            self._init_youtube()\n",
    "        except Exception as e:\n",
    "            print('Could not connect to the Google API Client:', e)\n",
    "        \n",
    "        Database.__init__(self, name=self.dir) # init self.conn and self.cursor\n",
    "        if self.conn is not None:\n",
    "            print('***** YouTube database directory: {} *****'.format(self.dir))\n",
    "    \n",
    "   \n",
    "    \n",
    "    ##################\n",
    "    # Public Methods #\n",
    "    ##################\n",
    "    \n",
    "    def create_structure(self):\n",
    "        \"\"\" Create the wap SQLite database structure (cf. data/sqlite_schema/sqlite_diagram.png).\n",
    "        SQL 'CREATE TABLE' statements available in 'data/sqlite_schema/*_schema.txt'\n",
    "        \"\"\"\n",
    "\n",
    "        def _create_table(create_table_sql):\n",
    "            \"\"\" Create a table from the create_table_sql statement\n",
    "            \n",
    "            :param str create_table_sql: a CREATE TABLE statement\n",
    "            \"\"\"\n",
    "            try:\n",
    "                self.query(create_table_sql)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        path = os.path.dirname(self.dir) + '/sqlite_schema'\n",
    "        with open(path + '/channels_schema.txt','r') as f:\n",
    "            sql_create_channels_table = f.read()\n",
    "        with open(path + '/comments_schema.txt','r') as f:\n",
    "            sql_create_comments_table = f.read()\n",
    "        with open(path + '/videos_schema.txt','r') as f:\n",
    "            sql_create_videos_table = f.read()\n",
    "        if self.conn is not None:\n",
    "            _create_table(sql_create_channels_table)\n",
    "            _create_table(sql_create_comments_table)\n",
    "            _create_table(sql_create_videos_table)\n",
    "            self.conn.commit()\n",
    "        else:\n",
    "            print(\"Error: Cannot create the database connection.\")\n",
    "    \n",
    "    \n",
    "    def display_schema(self):\n",
    "        \"\"\" Print the database schemas\n",
    "        \"\"\"\n",
    "        if not self.conn:\n",
    "            return\n",
    "        sql = \"SELECT SQL FROM sqlite_master WHERE TYPE = 'table'\"\n",
    "        self.query(sql)\n",
    "        tables = self.cursor.fetchall()\n",
    "        for table in tables:\n",
    "            print(*table, '\\n')\n",
    "    \n",
    "    \n",
    "    def get_comments_df(self, video_search=None, video_separator='OR',\n",
    "                        channel_search=None, channel_separator='OR',\n",
    "                        from_date=None, to_date=None):\n",
    "        \"\"\" Return a DataFrame of comments to the contents with the specified criterias\n",
    "        in the SQLite database\n",
    "\n",
    "        :param str video_search: Comma separated words for a keyword search in videos.title and videos.description\n",
    "        :param str video_separator: Choose between 'AND' (match every words) or 'OR' (match any word) for the `video_search` param\n",
    "        :param str channel_search: Comma separated words for a keyword search in channels.title and channels.description\n",
    "        :param str channel_separator: Choose between 'AND' (match every words) or 'OR' (match any word) for the `channel_search` param\n",
    "        :param datetime-like from_date: From specified comment published date\n",
    "        :param datetime-like to_date: To specified comment published date\n",
    "        \"\"\"\n",
    "        for separator in (video_separator, channel_separator):\n",
    "            if separator != 'AND' and separator !='OR':\n",
    "                raise ValueError(\"Valid values for the `_separator` params are 'AND' or 'OR', \"\n",
    "                                 \"the given value is invalid: '{}'\".format(separator))\n",
    "\n",
    "        condition_list = []\n",
    "        condition_list.append(self._format_datetime_condition(from_date, to_date))\n",
    "        condition_list.append(self._format_search_condition(video_search, video_separator,\n",
    "                                                            channel_search, channel_separator))\n",
    "        condition_list = list(filter(None, condition_list))\n",
    "        if condition_list:\n",
    "            conditions = 'WHERE' + ' AND '.join(condition_list)\n",
    "        else:\n",
    "            conditions = ''\n",
    "\n",
    "        sql = f\"\"\"\n",
    "            SELECT DISTINCT\n",
    "                comments.*,\n",
    "                channels.country\n",
    "            FROM\n",
    "                comments\n",
    "            INNER JOIN\n",
    "                videos ON videos.id = comments.videoId\n",
    "            INNER JOIN\n",
    "                channels ON channels.id = comments.authorChannelId\n",
    "            {conditions}\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(sql, self.conn)\n",
    "        df['publishedAt'] = pd.to_datetime(df['publishedAt'])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def run_analysis(self):\n",
    "        \"\"\" Run a sentiment analysis on the comments of the SQLite database\n",
    "        via MS Azure Text Analytics and an emotion analysis via\n",
    "        IBM Watson NLU if their detected language is supported by the APIs.\n",
    "        The analysis is stored in the SQLite database.\n",
    "        \"\"\"\n",
    "        self._update_language()\n",
    "#         self._update_sentiments()\n",
    "#         self._update_keywords()\n",
    "#         self._update_emotions()\n",
    "        self.conn.commit()\n",
    "    \n",
    "    \n",
    "    def search(self, query, n_results=5, n_comments=100, result_order='relevance', comment_order='relevance'):\n",
    "        \"\"\" Search specified videos on YouTube, and update the local database accordingly\n",
    "        with a sentiment and emotion analysis on the associated comments.\n",
    "        \n",
    "        For more information about the search options, please refer\n",
    "        to the documentation at:\n",
    "        https://developers.google.com/youtube/v3/docs/search/list\n",
    "        \n",
    "        :param str query: Query term to search for\n",
    "        :param int n_results: Number of search results desired\n",
    "        :param int n_comments: Number of comment threads per video desired\n",
    "        :param str result_order: Order of the search results in the API response\n",
    "        :param str comment_order: Order of the comment threads in the API response\n",
    "        \"\"\"\n",
    "        if self.youtube == None:\n",
    "            try:\n",
    "                self._init_youtube()\n",
    "            except Exception as e:\n",
    "                print('Could not connect to the Google API Client:', e)\n",
    "        \n",
    "        if result_order not in RESULT_ORDERS:\n",
    "            raise ValueError(\"Valid values for the `result_order` param are '{}', \"\n",
    "                             \"the given value is invalid: '{}'\"\n",
    "                             .format(\"', '\".join(RESULT_ORDERS), result_order))\n",
    "\n",
    "        if comment_order not in COMMENT_ORDERS:\n",
    "            raise ValueError(\"Valid values for the `result_order` param are '{}', \"\n",
    "                             \"the given value is invalid: '{}'\"\n",
    "                             .format(\"', '\".join(COMMENT_ORDERS), comment_order))\n",
    "        \n",
    "        page_token = None\n",
    "        for n in range(0, n_results, MAX_SEARCH):\n",
    "            # Maximum number of search results per page: 50\n",
    "            max_results = n_results - n if n_results - n <= MAX_SEARCH else MAX_SEARCH\n",
    "            search_response = self.youtube.search().list(\n",
    "                part='snippet',\n",
    "                maxResults=max_results,\n",
    "                order=result_order, # You may consider using 'viewCount'\n",
    "                pageToken=page_token,\n",
    "                q=query,\n",
    "                safeSearch='none',\n",
    "                type='video', # Channels might appear in search results\n",
    "            ).execute()\n",
    "            \n",
    "            self._insert_videos(search_response)\n",
    "            self._get_comments(n_comments, comment_order)\n",
    "           \n",
    "            if not 'nextPageToken' in search_response:\n",
    "                break\n",
    "            page_token = search_response['nextPageToken']\n",
    "    \n",
    "        self.conn.commit()\n",
    "    \n",
    "    \n",
    "    ###################\n",
    "    # Private Methods #\n",
    "    ###################\n",
    "        \n",
    "    def _format_comment_resource(self, comment_resource):\n",
    "        \"\"\" Format the comment resource into a list of tuples\n",
    "        for the SQLite query.\n",
    "        \n",
    "        :param dict comment_resource: Information about a single YouTube comment\n",
    "        :return: Specific values of the comment resource\n",
    "        :rtype: list\n",
    "        \"\"\"\n",
    "        if 'authorChannelId' in comment_resource['snippet'] \\\n",
    "          and 'value' in comment_resource['snippet']['authorChannelId']:\n",
    "            authorChannelId = comment_resource['snippet']['authorChannelId']['value']\n",
    "            self._insert_channel(authorChannelId)\n",
    "        else:\n",
    "            authorChannelId = None\n",
    "        \n",
    "        values = (\n",
    "            comment_resource['id'],\n",
    "            comment_resource['snippet']['videoId'],\n",
    "            authorChannelId,\n",
    "            str(pd.to_datetime(comment_resource['snippet']['publishedAt'])),\n",
    "            comment_resource['snippet']['likeCount'],\n",
    "            comment_resource['snippet']['parentId'] if 'parentId' in comment_resource['snippet'] else None,\n",
    "            comment_resource['snippet']['textDisplay']\n",
    "        )\n",
    "        return values\n",
    "    \n",
    "    \n",
    "    def _format_datetime_condition(self, from_date, to_date):\n",
    "        \"\"\" Return a condition for the SQLite 'WHERE' clause with the specified datetime range\n",
    "\n",
    "        :param datetime-like from_date: From specified comment published date\n",
    "        :param datetime-like to_date: To specified comment published date\n",
    "        :return: A condition for the SQLite 'WHERE' clause\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        if not from_date and not to_date:\n",
    "            return None\n",
    "        elif not from_date:\n",
    "            from_date = '1900-01-01 00:00:00'\n",
    "        elif not to_date:\n",
    "            to_date = 'now'\n",
    "        return \"(contents.published BETWEEN '{}' AND '{}')\".format(str(pd.to_datetime(from_date)),\n",
    "                                                                   str(pd.to_datetime(to_date)))\n",
    "    \n",
    "\n",
    "    def _format_search_condition(self, video_search, video_separator, channel_search, channel_separator):\n",
    "        \"\"\" Return a condition for the SQLite 'WHERE' clause with the specified search query.\n",
    "\n",
    "        :param str video_search: Comma separated words for a keyword search in videos.title and videos.description\n",
    "        :param str video_separator: Choose between 'AND' (match every words) or 'OR' (match any word) for the `video_search` param\n",
    "        :param str channel_search: Comma separated words for a keyword search in channels.title and channels.description\n",
    "        :param str channel_separator: Choose between 'AND' (match every words) or 'OR' (match any word) for the `channel_search` param\n",
    "        :return: A condition for the SQLite 'WHERE' clause\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        if not video_search and not channel_search:\n",
    "            return None\n",
    "        conditions = []\n",
    "        if video_search:\n",
    "            word_list = [\"'%{}%'\".format(word.strip()) for word in video_search.split(',') if word.strip()]\n",
    "            video_conditions = [f'videos.title LIKE {word} OR videos.description LIKE {word}'\n",
    "                                for word in word_list]\n",
    "            if video_conditions:\n",
    "                separator = f' {video_separator} '\n",
    "                conditions.append('({})'.format(separator.join(video_conditions)))\n",
    "        if channel_search:\n",
    "            word_list = [\"'%{}%'\".format(word.strip()) for word in channel_search.split(',') if word.strip()]\n",
    "            channel_conditions = [f'channels.title LIKE {word} OR channels.description LIKE {word}'\n",
    "                                  for word in word_list]\n",
    "            if channel_conditions:\n",
    "                separator = f' {video_separator} '\n",
    "                conditions.append('({})'.format(separator.join(channel_conditions)))\n",
    "        if len(conditions) == 1:\n",
    "            return conditions.pop()\n",
    "        return '({})'.format(' OR '.join(conditions))\n",
    "\n",
    "    \n",
    "    def _get_comments(self, n_comments, comment_order):\n",
    "        \"\"\" Get the comment threads to the videos found with the search request.\n",
    "        \n",
    "        :param int n_comments: Number of comment threads per video desired\n",
    "        :param str order: Order of the resources in the API response\n",
    "        \"\"\"\n",
    "        self.query('SELECT id FROM videos')\n",
    "        videoId_list = self.cursor.fetchall()\n",
    "        \n",
    "        for videoId in videoId_list:\n",
    "\n",
    "            page_token = None\n",
    "            for n in range(0, n_comments, MAX_SEARCH):\n",
    "                # Maximum number of comment threads per page: 100\n",
    "                max_comments = n_comments - n if n_comments - n <= MAX_COMMENT_THREADS else MAX_COMMENT_THREADS\n",
    "                \n",
    "                try:\n",
    "                    comment_response = self.youtube.commentThreads().list(\n",
    "                        part='snippet,replies',\n",
    "                        maxResults=max_comments,\n",
    "                        order=comment_order,\n",
    "                        pageToken=page_token,\n",
    "                        textFormat = 'plainText',\n",
    "                        videoId=videoId[0],\n",
    "                    ).execute()\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occured during the commmentThreads request of videoId '{videoId}':\", e)\n",
    "                    continue\n",
    "                self._insert_comments(comment_response)\n",
    "            \n",
    "                if not 'nextPageToken' in comment_response:\n",
    "                    break\n",
    "                page_token = comment_response['nextPageToken']\n",
    "\n",
    "    \n",
    "    def _init_youtube(self):\n",
    "        # Disable OAuthlib's HTTPS verification when running locally.\n",
    "        # *DO NOT* leave this option enabled in production.\n",
    "        os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "        \n",
    "        api_service_name = \"youtube\"\n",
    "        api_version = \"v3\"\n",
    "        self.youtube = build(\n",
    "            api_service_name,\n",
    "            api_version,\n",
    "            developerKey=self.googleApiKey\n",
    "        )\n",
    "    \n",
    "\n",
    "    def _insert_channel(self, channelId):\n",
    "        \"\"\" Insert the specified channel's info into the SQLite 'channels' table.\n",
    "\n",
    "        :param str channelId: Id of the channel\n",
    "        \"\"\"\n",
    "        try:\n",
    "            channel_response = self.youtube.channels().list(\n",
    "                part='snippet',\n",
    "                id=channelId\n",
    "            ).execute()\n",
    "        except Exception as e:\n",
    "            print(f\"An error occured during the channels request of channelId '{channelId}':\", e)\n",
    "            return\n",
    "        \n",
    "        if not 'items' in channel_response:\n",
    "            return\n",
    "        # The response should contain one item.\n",
    "        for channel_resource in channel_response['items']:\n",
    "            values = (\n",
    "                channel_resource['id'],\n",
    "                channel_resource['snippet']['title'],\n",
    "                channel_resource['snippet']['description'],\n",
    "                channel_resource['snippet']['country'] if 'country' in channel_resource['snippet'] else None\n",
    "            )\n",
    "            sql = f'INSERT OR {self.conflict_resolution} INTO channels VALUES(?,?,?,?)'\n",
    "            if not values:\n",
    "                return\n",
    "            self.cursor.execute(sql, values)\n",
    "    \n",
    "    \n",
    "    def _insert_comments(self, comment_response):\n",
    "        \"\"\" Insert the collection of comment threads into the SQLite 'comments' table.\n",
    "        \n",
    "        :param dict comment_ressource: Response to the commentThreads request\n",
    "        \"\"\"\n",
    "        if not 'items' in comment_response:\n",
    "            return\n",
    "                \n",
    "        value_list = []\n",
    "        for item in comment_response['items']:\n",
    "            values = self._format_comment_resource(item['snippet']['topLevelComment'])\n",
    "            value_list.append(values)\n",
    "            if 'replies' in item:\n",
    "                for comment in item['replies']['comments']:\n",
    "                    values = self._format_comment_resource(comment)\n",
    "                    value_list.append(values)\n",
    "       \n",
    "        cols = 'id,videoId,authorChannelId,publishedAt,likeCount,parentId,text'\n",
    "        sql = f'INSERT OR {self.conflict_resolution} INTO comments({cols}) VALUES(?,?,?,?,?,?,?)'\n",
    "        if not value_list:\n",
    "            return\n",
    "        self.cursor.executemany(sql, value_list)\n",
    "\n",
    "            \n",
    "    \n",
    "    def _insert_videos(self, search_response):\n",
    "        \"\"\" Insert the collection of search results into the SQLite 'videos' table.\n",
    "        \n",
    "        :param dict search_response: Response to the search request\n",
    "        \"\"\"\n",
    "        if not 'items' in search_response:\n",
    "            return\n",
    "        \n",
    "        value_list = []\n",
    "        for item in search_response['items']:\n",
    "            self._insert_channel(item['snippet']['channelId'])\n",
    "            values = (\n",
    "                item['id']['videoId'],\n",
    "                item['snippet']['channelId'],\n",
    "                str(pd.to_datetime(item['snippet']['publishedAt'])),\n",
    "                item['snippet']['title'],\n",
    "                item['snippet']['description']\n",
    "            )\n",
    "            value_list.append(values)\n",
    "        \n",
    "        sql = f'INSERT OR {self.conflict_resolution} INTO videos VALUES(?,?,?,?,?)'\n",
    "        if not value_list:\n",
    "            return\n",
    "        self.cursor.executemany(sql, value_list)\n",
    "   \n",
    "\n",
    "    def _update_emotions(self):\n",
    "        \"\"\" Update the 5 emotion columns of the 'comments' table\n",
    "        via IBM Watson's Natural Language Understanding API.\n",
    "        \"\"\"\n",
    "        sql_select = \"\"\"\n",
    "            SELECT id, text, text_en\n",
    "            FROM comments\n",
    "            WHERE anger IS NULL AND text IS NOT NULL\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(sql_select, self.conn)\n",
    "        df = df[df['language'].isin(WATSON_SUPPORTED_LANG)]\n",
    "        \n",
    "        if not df.empty:\n",
    "            sql_update = \"\"\"\n",
    "                UPDATE comments\n",
    "                SET anger = ?, disgust = ?, fear = ?, joy = ?, sadness = ?\n",
    "                WHERE id = ?\n",
    "            \"\"\"\n",
    "            values = get_emotions(df, self.watsonApiKey_nlu, self.watsonBaseUrl_nlu)\n",
    "            if values:\n",
    "                self.cursor.executemany(sql_update, values)\n",
    "                \n",
    "        # Set 'N/A' to comments not supported by the API\n",
    "        df = pd.read_sql_query(sql_select, self.conn)\n",
    "        sql_update = \"\"\"\n",
    "            UPDATE comments\n",
    "            SET anger = 'N/A', disgust = 'N/A', fear = 'N/A', joy = 'N/A', sadness = 'N/A'\n",
    "            WHERE id = ?\n",
    "        \"\"\"\n",
    "        values = [(row.id,) for row in df.itertuples()]\n",
    "        if values:\n",
    "            self.cursor.executemany(sql_update, values)\n",
    "\n",
    "\n",
    "    def _update_keywords(self):\n",
    "        \"\"\" Update the 'keywords' column of the 'comments' table\n",
    "        via MS Azure's Text Analytics API if the detected\n",
    "        language is supported by the API.\n",
    "        \"\"\"\n",
    "        sql_select = \"\"\"\n",
    "            SELECT id, language, text\n",
    "            FROM comments\n",
    "            WHERE keywords IS NULL AND text IS NOT NULL\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(sql_select, self.conn)\n",
    "        df = df[df['language'].isin(AZURE_SUPPORTED_LANG)]\n",
    "\n",
    "        if not df.empty:\n",
    "            key_phrases = []\n",
    "            for i in range(0, df.shape[0], 1000):\n",
    "                # maximum number of documents in a request: 1000\n",
    "                documents = {\n",
    "                    'documents': df.iloc[i:i + 1000].to_dict('records')\n",
    "                }\n",
    "                response = get_key_phrases(documents, self.azureApiKey, self.azureBaseUrl)\n",
    "                if 'documents' in response:\n",
    "                    key_phrases.extend(response['documents'])\n",
    "                # time sleep not to exceed the API requests limit\n",
    "                if i + 1000 < df.shape[0]:\n",
    "                    sleep(1)\n",
    "\n",
    "            sql_update = 'UPDATE comments SET keywords = ? WHERE id = ?'\n",
    "            values = [(','.join(elem['keyPhrases']), elem['id']) for elem in key_phrases]\n",
    "            if values:\n",
    "                self.cursor.executemany(sql_update, values)\n",
    "        \n",
    "        # Set 'N/A' to comments not supported by the API\n",
    "        df = pd.read_sql_query(sql_select, self.conn)\n",
    "        sql_update = \"UPDATE comments SET keywords = 'N/A' WHERE id = ?\"\n",
    "        values = [(row.id,) for row in df.itertuples()]\n",
    "        if values:\n",
    "            self.cursor.executemany(sql_update, values)\n",
    "\n",
    "\n",
    "    def _update_language(self):\n",
    "        \"\"\" Update the 'language' column of the 'comments' table.\n",
    "        \"\"\"        \n",
    "        if self.conflict_resolution == 'IGNORE':\n",
    "            sql_select = 'SELECT id, text FROM comments WHERE language IS NULL AND text IS NOT NULL'\n",
    "        else:\n",
    "            sql_select = 'SELECT id, text FROM comments WHERE text IS NOT NULL'\n",
    "        df = pd.read_sql_query(sql_select, self.conn)\n",
    "        if df.empty:\n",
    "            return\n",
    "\n",
    "        def detector(text):\n",
    "            try:\n",
    "                response = translate_client.detect_language(text)\n",
    "                return response['language']\n",
    "            except:\n",
    "                return 'unknown'\n",
    "        \n",
    "        translate_client = translate.Client()\n",
    "        df['language'] = df['text'].apply(detector)\n",
    "\n",
    "        sql_update = 'UPDATE comments SET language = ? WHERE id = ?'\n",
    "        values = [(elem.language, elem.id) for elem in df.itertuples()]\n",
    "        if not values:\n",
    "            return\n",
    "        self.cursor.executemany(sql_update, values)\n",
    "    \n",
    "\n",
    "    def _update_sentiments(self):\n",
    "        \"\"\" Update the 'sentimentScore' and 'sentimentLabel' columns of the 'comments' table\n",
    "        via MS Azure's Text Analytics API.\n",
    "        \"\"\"\n",
    "        sql_select = \"\"\"\n",
    "            SELECT id, language, text\n",
    "            FROM comments\n",
    "            WHERE sentimentScore IS NULL AND text IS NOT NULL\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(sql_select, self.conn)\n",
    "        df = df[df['language'].isin(AZURE_SUPPORTED_LANG)]\n",
    "\n",
    "        if not df.empty:\n",
    "            sentiments = []\n",
    "            for i in range(0, df.shape[0], 1000):\n",
    "                # maximum number of documents in a request: 1000\n",
    "                documents = {\n",
    "                    'documents': df.iloc[i:i + 1000].to_dict('records')\n",
    "                }\n",
    "                response = get_sentiments(documents, self.azureApiKey, self.azureBaseUrl)\n",
    "                if 'documents' in response:\n",
    "                    sentiments.extend(response['documents'])\n",
    "                # time sleep not to exceed the API requests limit\n",
    "                if i + 1000 < df.shape[0]:\n",
    "                    sleep(1)\n",
    "\n",
    "            for elem in sentiments:\n",
    "                if elem['score'] < 0.4:\n",
    "                    elem['label'] = 'negative'\n",
    "                elif elem['score'] < 0.7:\n",
    "                    elem['label'] = 'neutral'\n",
    "                else:\n",
    "                    elem['label'] = 'positive'\n",
    "\n",
    "            sql_update = \"\"\"\n",
    "                UPDATE comments\n",
    "                SET sentimentLabel = ?, sentimentScore = ?\n",
    "                WHERE id = ?\n",
    "            \"\"\"\n",
    "            values = [(elem['label'], elem['score'], elem['id']) for elem in sentiments]\n",
    "            if values:\n",
    "                self.cursor.executemany(sql_update, values)\n",
    "        \n",
    "        # Set 'N/A' to comments not supported by the API\n",
    "        df = pd.read_sql_query(sql_select, self.conn)\n",
    "        sql_update = \"\"\"\n",
    "            UPDATE comments\n",
    "            SET sentimentLabel = 'N/A', sentimentScore = 'N/A'\n",
    "            WHERE id = ?\n",
    "        \"\"\"\n",
    "        values = [(row.id,) for row in df.itertuples()]\n",
    "        if values:\n",
    "            self.cursor.executemany(sql_update, values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_search = 'aaa,  bb, ,'\n",
    "video_separator = 'OR'\n",
    "channel_search = ',ccc'\n",
    "channel_separator = 'AND'\n",
    "db._format_search_condition(video_search, video_separator, channel_search, channel_separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('MY_CREDENTIALS.json', 'r') as f:\n",
    "#     credentials = json.load(f)\n",
    "\n",
    "db = youtubeAnalyzer(\n",
    "#     googleApiKey=credentials['google_developer_key'],\n",
    "#     azureApiKey=credentials['azure_subscription_key'],\n",
    "#     azureBaseUrl=credentials['azure_text_analytics_base_url'],\n",
    "#     watsonApiKey=credentials['watson_nlu_api_key'],\n",
    "#     watsonBaseUrl=credentials['watson_nlu_base_url']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db.create_structure()\n",
    "db.display_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# db.query('DROP TABLE channels')\n",
    "# db.conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# db.search(\n",
    "#     query='cookies',\n",
    "#     n_results=5,\n",
    "#     n_comments=5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db._update_language()\n",
    "db.conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT * FROM comments WHERE publishedAt > 2018 anD videoId = '3vUtRRZG0xY'\" \n",
    "db.query(sql)\n",
    "tmp = db.cursor.fetchall()\n",
    "len(tmp)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db.get_comments_df(\n",
    "    video_search='chocolate, cream'\n",
    ")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    continue\n",
    "    print('test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
