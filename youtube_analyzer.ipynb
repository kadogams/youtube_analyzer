{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A class to make a sentiment and emotion analysis on Youtube comments.\n",
    "The analysis are saved locally in an SQLite database.\n",
    "Database schema available at 'data/sqlite_schema/sqlite_diagram.png'\n",
    "\n",
    "requirements:\n",
    " - google-api-python-client\n",
    " - ibm-watson\n",
    " - langdetect\n",
    " - pandas\n",
    "\n",
    "API keys required for:\n",
    " - Google API\n",
    " - Microsoft Azure Text Analytics API\n",
    " - IBM Watson Natural Language Understanding API\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from langdetect import detect\n",
    "import pandas as pd\n",
    "\n",
    "from sqlite3_wrapper.database import Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite\n",
    "CONFLIT_RESOLUTION_ALGORITHMS = ['ROLLBACK', 'ABORT', 'FAIL', 'IGNORE', 'REPLACE']\n",
    "\n",
    "# Google API Client\n",
    "MAX_SEARCH = 50\n",
    "MAX_COMMENT_THREADS = 100\n",
    "RESULT_ORDERS = ['date', 'rating', 'relevance', 'title', 'videoCount', 'viewCount']\n",
    "COMMENT_ORDERS = ['time', 'relevance']\n",
    "\n",
    "# MS Azure (supported languages for both sentiment analysis and key phrases extraction)\n",
    "AZURE_SUPPORTED_LANG = ['da', 'nl', 'en', 'fi', 'fr', 'de', 'it', 'no', 'pl', 'pt', 'ru', 'es', 'sv']\n",
    "\n",
    "# IBM Watson (supported languages for emotion analysis)\n",
    "WATSON_SUPPORTED_LANG = ['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class youtubeAnalyzer(Database):\n",
    "    \"\"\" A class to manage the YouTube SQLite database.\n",
    "    Inherits from base class 'Database' in database.py (a wrapper around the sqlite3 python library)\n",
    "    Database schema available at 'data/sqlite_schema/sqlite_diagram.png'\n",
    "    \"\"\"\n",
    "\n",
    "    #################\n",
    "    # Magic Methods #\n",
    "    #################\n",
    "\n",
    "    def __init__(self, googleApiKey=None, azureApiKey=None, watsonApiKey=None,\n",
    "                 azureBaseUrl='https://westcentralus.api.cognitive.microsoft.com/text/analytics/v2.1/',\n",
    "                 watsonBaseUrl='https://gateway-lon.watsonplatform.net/natural-language-understanding/api',\n",
    "                 conflict_resolution='IGNORE', sqlite_file='youtube.sqlite'):\n",
    "        \"\"\"\n",
    "        :param str googleApiKey: Developper key for Google API\n",
    "        :param str azureApiKey: Subscription key for Azure Text Analytics API\n",
    "        :param str watsonApiKey: API key for IBM Watson's Natural Language Understanding API\n",
    "        :param str jiveBaseUrl: WAP url\n",
    "        :param str azureBaseUrl: Base url for Azure Text Analytics API\n",
    "        :param str watsonBaseUrl_nlu: Base url for IBM Watson's Natural Language Understanding API\n",
    "        :param str conflict_resolution: ON CONFLICT clause for the SQLite queries. Warning: 'REPLACE' will delete the all Azure and Watson analysis.\n",
    "        :param str sqlite_file: SQLite file name\n",
    "        \"\"\"\n",
    "        if conflict_resolution not in CONFLIT_RESOLUTION_ALGORITHMS:\n",
    "            raise ValueError(\"Valid values for the `conflict_resolution` param are '{}', \"\n",
    "                             \"the given value is invalid: '{}'\"\n",
    "                             .format(\"', '\".join(CONFLIT_RESOLUTION_ALGORITHMS), conflict_resolution))\n",
    "\n",
    "#         path = os.path.dirname(os.path.abspath(__file__)) + '/data'\n",
    "        path = os.getcwd() + '/data'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        self.dir = path + '/' + sqlite_file\n",
    "        self.conn = None\n",
    "        self.cursor = None\n",
    "        self.conflict_resolution = conflict_resolution\n",
    "        \n",
    "        self.googleApiKey = googleApiKey\n",
    "        self.azureApiKey = azureApiKey\n",
    "        self.azureBaseUrl = azureBaseUrl\n",
    "        self.watsonApiKey = watsonApiKey\n",
    "        self.watsonBaseUrl = watsonBaseUrl\n",
    "\n",
    "        try:\n",
    "            self._init_youtube()\n",
    "        except Exception as e:\n",
    "            print('Could not connect to the Google API Client:', e)\n",
    "        \n",
    "        Database.__init__(self, name=self.dir) # init self.conn and self.cursor\n",
    "        if self.conn is not None:\n",
    "            print('***** YouTube database directory: {} *****'.format(self.dir))\n",
    "    \n",
    "    \n",
    "    def get_comments_df(self, video_search=None, video_separator='OR',\n",
    "                        channel_search=None, channel_separator='OR',\n",
    "                        from_date=None, to_date=None):\n",
    "        \"\"\" Return a DataFrame of comments to the contents with the specified criterias\n",
    "        in the SQLite database\n",
    "\n",
    "        :param str video_search: Comma separated words for a keyword search in videos.title and videos.description\n",
    "        :param str video_separator: Choose between 'AND' (match every words) or 'OR' (match any word) for the `video_search` param\n",
    "        :param str channel_search: Comma separated words for a keyword search in channels.title and channels.description\n",
    "        :param str channel_separator: Choose between 'AND' (match every words) or 'OR' (match any word) for the `channel_search` param\n",
    "        :param datetime-like from_date: From specified comment published date\n",
    "        :param datetime-like to_date: To specified comment published date\n",
    "        \"\"\"\n",
    "        for separator in (video_separator, channel_separator):\n",
    "            if separator != 'AND' and separator !='OR':\n",
    "                raise ValueError(\"Valid values for the `_separator` params are 'AND' or 'OR', \"\n",
    "                                 \"the given value is invalid: '{}'\".format(separator))\n",
    "\n",
    "        condition_list = []\n",
    "        condition_list.append(self._format_datetime_condition(from_date, to_date))\n",
    "        condition_list.append(self._format_search_condition(video_search, video_separator,\n",
    "                                                            channel_search, channel_separator))\n",
    "        condition_list = list(filter(None, condition_list))\n",
    "        if condition_list:\n",
    "            conditions = 'WHERE' + ' AND '.join(condition_list)\n",
    "        else:\n",
    "            conditions = ''\n",
    "\n",
    "        sql = f\"\"\"\n",
    "            SELECT DISTINCT\n",
    "                comments.*,\n",
    "                channels.country\n",
    "            FROM\n",
    "                comments\n",
    "            INNER JOIN\n",
    "                videos ON videos.id = comments.videoId\n",
    "            INNER JOIN\n",
    "                channels ON channels.id = comments.authorChannelId\n",
    "            {conditions}\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(sql, self.conn)\n",
    "        df['publishedAt'] = pd.to_datetime(df['publishedAt'])\n",
    "        return df\n",
    "\n",
    "    \n",
    "    \n",
    "    ##################\n",
    "    # Public Methods #\n",
    "    ##################\n",
    "    \n",
    "    def create_structure(self):\n",
    "        \"\"\" Create the wap SQLite database structure (cf. data/sqlite_schema/sqlite_diagram.png).\n",
    "        SQL 'CREATE TABLE' statements available in 'data/sqlite_schema/*_schema.txt'\n",
    "        \"\"\"\n",
    "\n",
    "        def _create_table(create_table_sql):\n",
    "            \"\"\" Create a table from the create_table_sql statement\n",
    "            \n",
    "            :param str create_table_sql: a CREATE TABLE statement\n",
    "            \"\"\"\n",
    "            try:\n",
    "                self.query(create_table_sql)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        path = os.path.dirname(self.dir) + '/sqlite_schema'\n",
    "        with open(path + '/channels_schema.txt','r') as f:\n",
    "            sql_create_channels_table = f.read()\n",
    "        with open(path + '/comments_schema.txt','r') as f:\n",
    "            sql_create_comments_table = f.read()\n",
    "        with open(path + '/videos_schema.txt','r') as f:\n",
    "            sql_create_videos_table = f.read()\n",
    "        if self.conn is not None:\n",
    "            _create_table(sql_create_channels_table)\n",
    "            _create_table(sql_create_comments_table)\n",
    "            _create_table(sql_create_videos_table)\n",
    "        else:\n",
    "            print(\"Error: Cannot create the database connection.\")\n",
    "    \n",
    "    \n",
    "    def display_schema(self):\n",
    "        \"\"\" Print the database schemas\n",
    "        \"\"\"\n",
    "        if not self.conn:\n",
    "            return\n",
    "        sql = \"SELECT SQL FROM sqlite_master WHERE TYPE = 'table'\"\n",
    "        self.query(sql)\n",
    "        tables = self.cursor.fetchall()\n",
    "        for table in tables:\n",
    "            print(*table, '\\n')\n",
    "    \n",
    "    \n",
    "    def run_analysis(self):\n",
    "        \"\"\" Run a sentiment analysis via MS Azure Text Analytics and\n",
    "        an emotion analysis via IBM Watson NLU on comments\n",
    "        if their detected language is supported by the APIs.\n",
    "        The analysis is stored in the SQLite database.\n",
    "        \"\"\"\n",
    "        self._detect_language()\n",
    "    \n",
    "    \n",
    "    def search(self, query, n_results=5, n_comments=100, result_order='relevance', comment_order='relevance'):\n",
    "        \"\"\" Search specified videos on YouTube, and update the local database accordingly\n",
    "        with a sentiment and emotion analysis on the associated comments.\n",
    "        \n",
    "        For more information about the search options, please refer\n",
    "        to the documentation at:\n",
    "        https://developers.google.com/youtube/v3/docs/search/list\n",
    "        \n",
    "        :param str query: Query term to search for\n",
    "        :param int n_results: Number of search results desired\n",
    "        :param int n_comments: Number of comment threads per video desired\n",
    "        :param str result_order: Order of the search results in the API response\n",
    "        :param str comment_order: Order of the comment threads in the API response\n",
    "        \"\"\"\n",
    "        if self.youtube == None:\n",
    "            try:\n",
    "                self._init_youtube()\n",
    "            except Exception as e:\n",
    "                print('Could not connect to the Google API Client:', e)\n",
    "        \n",
    "        if result_order not in RESULT_ORDERS:\n",
    "            raise ValueError(\"Valid values for the `result_order` param are '{}', \"\n",
    "                             \"the given value is invalid: '{}'\"\n",
    "                             .format(\"', '\".join(RESULT_ORDERS), result_order))\n",
    "\n",
    "        if comment_order not in COMMENT_ORDERS:\n",
    "            raise ValueError(\"Valid values for the `result_order` param are '{}', \"\n",
    "                             \"the given value is invalid: '{}'\"\n",
    "                             .format(\"', '\".join(COMMENT_ORDERS), comment_order))\n",
    "        \n",
    "        page_token = None\n",
    "        for n in range(0, n_results, MAX_SEARCH):\n",
    "            # Maximum number of search results per page: 50\n",
    "            max_results = n_results - n if n_results - n <= MAX_SEARCH else MAX_SEARCH\n",
    "            search_response = self.youtube.search().list(\n",
    "                part='snippet',\n",
    "                maxResults=max_results,\n",
    "                order=result_order, # You may consider using 'viewCount'\n",
    "                pageToken=page_token,\n",
    "                q=query,\n",
    "                safeSearch='none',\n",
    "                type='video', # Channels might appear in search results\n",
    "            ).execute()\n",
    "            \n",
    "            self._insert_videos(search_response)\n",
    "            self._get_comments(n_comments, comment_order)\n",
    "            \n",
    "            if not 'nextPageToken' in search_response:\n",
    "                break\n",
    "            page_token = search_response['nextPageToken']\n",
    "    \n",
    "    \n",
    "    ###################\n",
    "    # Private Methods #\n",
    "    ###################\n",
    "    \n",
    "    \n",
    "    def _init_youtube(self):\n",
    "        # Disable OAuthlib's HTTPS verification when running locally.\n",
    "        # *DO NOT* leave this option enabled in production.\n",
    "        os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "        \n",
    "        api_service_name = \"youtube\"\n",
    "        api_version = \"v3\"\n",
    "        self.youtube = build(\n",
    "            api_service_name,\n",
    "            api_version,\n",
    "            developerKey=self.googleApiKey\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def _format_comment_resource(self, comment_resource):\n",
    "        \"\"\" Format the comment resource into a list of tuples\n",
    "        for the SQLite query.\n",
    "        \n",
    "        :param dict comment_resource: Information about a single YouTube comment\n",
    "        :return: Specific values of the comment resource\n",
    "        :rtype: list\n",
    "        \"\"\"\n",
    "        if 'authorChannelId' in comment_resource['snippet'] \\\n",
    "          and 'value' in comment_resource['snippet']['authorChannelId']:\n",
    "            authorChannelId = comment_resource['snippet']['authorChannelId']['value']\n",
    "            self._insert_channel(authorChannelId)\n",
    "        else:\n",
    "            authorChannelId = None\n",
    "        \n",
    "        values = (\n",
    "            comment_resource['id'],\n",
    "            comment_resource['snippet']['videoId'],\n",
    "            authorChannelId,\n",
    "            str(pd.to_datetime(comment_resource['snippet']['publishedAt'])),\n",
    "            comment_resource['snippet']['likeCount'],\n",
    "            comment_resource['snippet']['parentId'] if 'parentId' in comment_resource['snippet'] else None,\n",
    "            comment_resource['snippet']['textDisplay']\n",
    "        )\n",
    "        return values\n",
    "    \n",
    "    \n",
    "    def _format_datetime_condition(self, from_date, to_date):\n",
    "        \"\"\" Return a condition for the SQLite 'WHERE' clause with the specified datetime range\n",
    "\n",
    "        :param datetime-like from_date: From specified comment published date\n",
    "        :param datetime-like to_date: To specified comment published date\n",
    "        :return: A condition for the SQLite 'WHERE' clause\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        if not from_date and not to_date:\n",
    "            return None\n",
    "        elif not from_date:\n",
    "            from_date = '1900-01-01 00:00:00'\n",
    "        elif not to_date:\n",
    "            to_date = 'now'\n",
    "        return \"(contents.published BETWEEN '{}' AND '{}')\".format(str(pd.to_datetime(from_date)),\n",
    "                                                                   str(pd.to_datetime(to_date)))\n",
    "    \n",
    "\n",
    "    def _format_search_condition(self, video_search, video_separator, channel_search, channel_separator):\n",
    "        \"\"\" Return a condition for the SQLite 'WHERE' clause with the specified search query.\n",
    "\n",
    "        :param str video_search: Comma separated words for a keyword search in videos.title and videos.description\n",
    "        :param str video_separator: Choose between 'AND' (match every words) or 'OR' (match any word) for the `video_search` param\n",
    "        :param str channel_search: Comma separated words for a keyword search in channels.title and channels.description\n",
    "        :param str channel_separator: Choose between 'AND' (match every words) or 'OR' (match any word) for the `channel_search` param\n",
    "        :return: A condition for the SQLite 'WHERE' clause\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        if not video_search and not channel_search:\n",
    "            return None\n",
    "        conditions = []\n",
    "        if video_search:\n",
    "            word_list = [\"'%{}%'\".format(word.strip()) for word in video_search.split(',') if word.strip()]\n",
    "            video_conditions = [f'videos.title LIKE {word} OR videos.description LIKE {word}'\n",
    "                                for word in word_list]\n",
    "            if video_conditions:\n",
    "                separator = f' {video_separator} '\n",
    "                conditions.append('({})'.format(separator.join(video_conditions)))\n",
    "        if channel_search:\n",
    "            word_list = [\"'%{}%'\".format(word.strip()) for word in channel_search.split(',') if word.strip()]\n",
    "            channel_conditions = [f'channels.title LIKE {word} OR channels.description LIKE {word}'\n",
    "                                  for word in word_list]\n",
    "            if channel_conditions:\n",
    "                separator = f' {video_separator} '\n",
    "                conditions.append('({})'.format(separator.join(channel_conditions)))\n",
    "        if len(conditions) == 1:\n",
    "            return conditions.pop()\n",
    "        return '({})'.format(' OR '.join(conditions))\n",
    "\n",
    "    \n",
    "    def _get_comments(self, n_comments, comment_order):\n",
    "        \"\"\" Get the comment threads to the videos found with the search request.\n",
    "        \n",
    "        :param int n_comments: Number of comment threads per video desired\n",
    "        :param str order: Order of the resources in the API response\n",
    "        \"\"\"\n",
    "        self.query('SELECT id FROM videos')\n",
    "        videoId_list = self.cursor.fetchall()\n",
    "        \n",
    "        for videoId in videoId_list:\n",
    "\n",
    "            page_token = None\n",
    "            for n in range(0, n_comments, MAX_SEARCH):\n",
    "                # Maximum number of comment threads per page: 100\n",
    "                max_comments = n_comments - n if n_comments - n <= MAX_COMMENT_THREADS else MAX_COMMENT_THREADS\n",
    "                \n",
    "                try:\n",
    "                    comment_response = self.youtube.commentThreads().list(\n",
    "                        part='snippet,replies',\n",
    "                        maxResults=max_comments,\n",
    "                        order=comment_order,\n",
    "                        pageToken=page_token,\n",
    "                        textFormat = 'plainText',\n",
    "                        videoId=videoId[0],\n",
    "                    ).execute()\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occured during the commmentThreads request of videoId '{videoId}':\", e)\n",
    "                    continue\n",
    "                self._insert_comments(comment_response)\n",
    "            \n",
    "                if not 'nextPageToken' in comment_response:\n",
    "                    break\n",
    "                page_token = comment_response['nextPageToken']\n",
    "\n",
    "    \n",
    "    def _insert_channel(self, channelId):\n",
    "        \"\"\" Insert the specified channel's info into the SQLite 'channels' table.\n",
    "\n",
    "        :param str channelId: Id of the channel\n",
    "        \"\"\"\n",
    "        try:\n",
    "            channel_response = self.youtube.channels().list(\n",
    "                part='snippet',\n",
    "                id=channelId\n",
    "            ).execute()\n",
    "        except Exception as e:\n",
    "            print(f\"An error occured during the channels request of channelId '{channelId}':\", e)\n",
    "            return\n",
    "        \n",
    "        if not 'items' in channel_response:\n",
    "            return\n",
    "        # The response should contain one item.\n",
    "        for channel_resource in channel_response['items']:\n",
    "            values = (\n",
    "                channel_resource['id'],\n",
    "                channel_resource['snippet']['title'],\n",
    "                channel_resource['snippet']['description'],\n",
    "                channel_resource['snippet']['country'] if 'country' in channel_resource['snippet'] else None\n",
    "            )\n",
    "            sql = f'INSERT OR {self.conflict_resolution} INTO channels VALUES(?,?,?,?)'\n",
    "            if not values:\n",
    "                return\n",
    "            self.cursor.execute(sql, values)\n",
    "    \n",
    "    \n",
    "    def _insert_comments(self, comment_response):\n",
    "        \"\"\" Insert the collection of comment threads into the SQLite 'comments' table.\n",
    "        \n",
    "        :param dict comment_ressource: Response to the commentThreads request\n",
    "        \"\"\"\n",
    "        if not 'items' in comment_response:\n",
    "            return\n",
    "                \n",
    "        value_list = []\n",
    "        for item in comment_response['items']:\n",
    "            values = self._format_comment_resource(item['snippet']['topLevelComment'])\n",
    "            value_list.append(values)\n",
    "            if 'replies' in item:\n",
    "                for comment in item['replies']['comments']:\n",
    "                    values = self._format_comment_resource(comment)\n",
    "                    value_list.append(values)\n",
    "       \n",
    "        cols = 'id,videoId,authorChannelId,publishedAt,likeCount,parentId,textDisplay'\n",
    "        sql = f'INSERT OR {self.conflict_resolution} INTO comments({cols}) VALUES(?,?,?,?,?,?,?)'\n",
    "        if not value_list:\n",
    "            return\n",
    "        self.cursor.executemany(sql, value_list)\n",
    "\n",
    "            \n",
    "    \n",
    "    def _insert_videos(self, search_response):\n",
    "        \"\"\" Insert the collection of search results into the SQLite 'videos' table.\n",
    "        \n",
    "        :param dict search_response: Response to the search request\n",
    "        \"\"\"\n",
    "        if not 'items' in search_response:\n",
    "            return\n",
    "        \n",
    "        value_list = []\n",
    "        for item in search_response['items']:\n",
    "            self._insert_channel(item['snippet']['channelId'])\n",
    "            values = (\n",
    "                item['id']['videoId'],\n",
    "                item['snippet']['channelId'],\n",
    "                str(pd.to_datetime(item['snippet']['publishedAt'])),\n",
    "                item['snippet']['title'],\n",
    "                item['snippet']['description']\n",
    "            )\n",
    "            value_list.append(values)\n",
    "        \n",
    "        sql = f'INSERT OR {self.conflict_resolution} INTO videos VALUES(?,?,?,?,?)'\n",
    "        if not value_list:\n",
    "            return\n",
    "        self.cursor.executemany(sql, value_list)\n",
    "    \n",
    "    \n",
    "    def _update_language(self):\n",
    "        \"\"\" Update the 'language' column of the 'comments' table.\n",
    "        \"\"\"\n",
    "        if self.conflict_resolution == 'IGNORE':\n",
    "            sql = 'SELECT id, textDisplay FROM comments WHERE language IS NULL AND textDisplay IS NOT NULL'\n",
    "        else:\n",
    "            sql = 'SELECT id, textDisplay FROM comments WHERE textDisplay IS NOT NULL'\n",
    "        df = pd.read_sql_query(sql, self.conn)\n",
    "        if df.empty:\n",
    "            return\n",
    "\n",
    "        def detector(text):\n",
    "            try:\n",
    "                return detect(text)\n",
    "            except:\n",
    "                return 'unknown'\n",
    "        \n",
    "        df['language'] = df['textDisplay'].apply(detector)\n",
    "\n",
    "        sql = 'UPDATE comments SET language = ? WHERE id = ?'\n",
    "        values = [(elem.language, elem.id) for elem in df.itertuples()]\n",
    "        if not values:\n",
    "            return\n",
    "        self.cursor.executemany(sql, values)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"((videos.title LIKE '%aaa%' OR videos.description LIKE '%aaa%' OR videos.title LIKE '%bb%' OR videos.description LIKE '%bb%') OR (channels.title LIKE '%ccc%' OR channels.description LIKE '%ccc%'))\""
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_search = 'aaa,  bb, ,'\n",
    "video_separator = 'OR'\n",
    "channel_search = ',ccc'\n",
    "channel_separator = 'AND'\n",
    "db._format_search_condition(video_search, video_separator, channel_search, channel_separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** YouTube database directory: /home/kadogams/dev/youtube/data/youtube.sqlite *****\n"
     ]
    }
   ],
   "source": [
    "with open('MY_CREDENTIALS.json', 'r') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "db = youtubeAnalyzer(\n",
    "    googleApiKey=credentials['google_developer_key'],\n",
    "    azureApiKey=credentials['azure_subscription_key'],\n",
    "    azureBaseUrl=credentials['azure_text_analytics_base_url'],\n",
    "    watsonApiKey=credentials['watson_nlu_api_key'],\n",
    "    watsonBaseUrl=credentials['watson_nlu_base_url']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db.create_structure()\n",
    "db.display_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# db.query('DROP TABLE channels')\n",
    "# db.conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# db.search(\n",
    "#     query='cookies',\n",
    "#     n_results=5,\n",
    "#     n_comments=5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "db._update_language()\n",
    "db.conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('UggDVyFRigOTpHgCoAEC',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCH1Km92YMKamOCI8llgvpcQ',\n",
       "  '2017-06-14 16:05:56+00:00',\n",
       "  6473,\n",
       "  None,\n",
       "  'If only you could eat through a screen...',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UggDVyFRigOTpHgCoAEC.8TnNRbA0PhU8xrRY9PdW7V',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCpPGIOUSuBxEv4xe_7QcSug',\n",
       "  '2019-07-26 18:11:57+00:00',\n",
       "  0,\n",
       "  'UggDVyFRigOTpHgCoAEC',\n",
       "  'Lol yea..you could try it yourself tho...',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UggDVyFRigOTpHgCoAEC.8TnNRbA0PhU8xpTGz6-SZq',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCYcbuUwBi-g6uxb_CtfoJ7w',\n",
       "  '2019-07-25 23:48:36+00:00',\n",
       "  0,\n",
       "  'UggDVyFRigOTpHgCoAEC',\n",
       "  'Yep',\n",
       "  'tr',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UggDVyFRigOTpHgCoAEC.8TnNRbA0PhU8xkXDaB5Ac9',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UChg9qsKsPocukcpVosVg0Ow',\n",
       "  '2019-07-24 01:46:53+00:00',\n",
       "  0,\n",
       "  'UggDVyFRigOTpHgCoAEC',\n",
       "  'Mint_Pickles im making them right now😂',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UggDVyFRigOTpHgCoAEC.8TnNRbA0PhU8xSx-U4qV4o',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCKVomELtRPBSpeMofG-QFOg',\n",
       "  '2019-07-16 20:35:19+00:00',\n",
       "  0,\n",
       "  'UggDVyFRigOTpHgCoAEC',\n",
       "  'Quý cô gà non i just did it 🙈',\n",
       "  'fr',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UggDVyFRigOTpHgCoAEC.8TnNRbA0PhU8xCJ3WZr0XT',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCPuPZ9-F5wZ6tGGtTgN0jHA',\n",
       "  '2019-07-10 09:29:46+00:00',\n",
       "  0,\n",
       "  'UggDVyFRigOTpHgCoAEC',\n",
       "  'Lol true',\n",
       "  'es',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgzMuigr0a4m1QGCOvB4AaABAg',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UC4MDGUTNP-TolgC09ykQ5jA',\n",
       "  '2019-05-15 02:55:08+00:00',\n",
       "  1241,\n",
       "  None,\n",
       "  'Why did I decide to search up “tasty desserts” while fasting? 🤦🏽\\u200d♀️',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgzMuigr0a4m1QGCOvB4AaABAg.8uwPO8lsY6C8xqQ0aSR0P7',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCgJMsCMX-vUVJ5Y6XcYcynw',\n",
       "  '2019-07-26 08:39:24+00:00',\n",
       "  0,\n",
       "  'UgzMuigr0a4m1QGCOvB4AaABAg',\n",
       "  'I love cooking and my parents have a bakery..... fasting is hell for me 😩',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgzMuigr0a4m1QGCOvB4AaABAg.8uwPO8lsY6C8xpg_Snq4kc',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UC6dK-6xY_gKwHL_-6nGAMPQ',\n",
       "  '2019-07-26 01:53:36+00:00',\n",
       "  0,\n",
       "  'UgzMuigr0a4m1QGCOvB4AaABAg',\n",
       "  'i m a n ! ! I’ve never related to a comment this much',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgzMuigr0a4m1QGCOvB4AaABAg.8uwPO8lsY6C8xa2AubMrHi',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCJvxrr_1tnconOFB6WmUvXw',\n",
       "  '2019-07-20 00:03:14+00:00',\n",
       "  0,\n",
       "  'UgzMuigr0a4m1QGCOvB4AaABAg',\n",
       "  '@Minahil Syal  HAPPPY RAMADAN ALTHOUGH ITS PAST',\n",
       "  'tl',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgzMuigr0a4m1QGCOvB4AaABAg.8uwPO8lsY6C8x_JLUsQlXW',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UC84lCV2fVdPfq6ROWmnak3w',\n",
       "  '2019-07-19 17:13:59+00:00',\n",
       "  0,\n",
       "  'UgzMuigr0a4m1QGCOvB4AaABAg',\n",
       "  'To test determination',\n",
       "  'it',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('Ugz0mnBKSKmdlHG3CPh4AaABAg',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UC0MwTBzFlFJsiE6QQoVQSvg',\n",
       "  '2019-02-05 05:22:08+00:00',\n",
       "  523,\n",
       "  None,\n",
       "  'When you read the comments when the cookies are cooking and everyone is saying to reduce the sugar. Oh Dang.',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('Ugz0mnBKSKmdlHG3CPh4AaABAg.8qxkWD6HNBq8xW2Q4Q0d0X',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCp_qiInY_N9m8ynP99LhKSw',\n",
       "  '2019-07-18 01:29:06+00:00',\n",
       "  1,\n",
       "  'Ugz0mnBKSKmdlHG3CPh4AaABAg',\n",
       "  'I just tried it, and reduce the god damn sugar',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('Ugz0mnBKSKmdlHG3CPh4AaABAg.8qxkWD6HNBq8xTsNyZ4XrO',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCiTcD60b7grh1Jb8TppBIhw',\n",
       "  '2019-07-17 05:14:13+00:00',\n",
       "  0,\n",
       "  'Ugz0mnBKSKmdlHG3CPh4AaABAg',\n",
       "  'omg me too ahhh',\n",
       "  'so',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('Ugz0mnBKSKmdlHG3CPh4AaABAg.8qxkWD6HNBq8xR0EDGLZLD',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCtZAsnbKqqXUn6ZEf1T8Ndw',\n",
       "  '2019-07-16 02:33:48+00:00',\n",
       "  0,\n",
       "  'Ugz0mnBKSKmdlHG3CPh4AaABAg',\n",
       "  'BRO SAME',\n",
       "  'pt',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('Ugz0mnBKSKmdlHG3CPh4AaABAg.8qxkWD6HNBq8xJHESClkxZ',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UC2PqWpyQ3aeB0FMi7DycpUw',\n",
       "  '2019-07-13 02:28:28+00:00',\n",
       "  0,\n",
       "  'Ugz0mnBKSKmdlHG3CPh4AaABAg',\n",
       "  'This happened to me today ughhhh😩😭',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('Ugz0mnBKSKmdlHG3CPh4AaABAg.8qxkWD6HNBq8xGAZBW_IVw',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCjhy3GTpKz7_tNfa9IN8yaQ',\n",
       "  '2019-07-11 21:32:24+00:00',\n",
       "  0,\n",
       "  'Ugz0mnBKSKmdlHG3CPh4AaABAg',\n",
       "  'Same lol how did urs turn out?',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgynHTik7JNIBbrJdUV4AaABAg',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCotCLMM5mauoaahJ0LqYB2g',\n",
       "  '2018-10-24 21:34:00+00:00',\n",
       "  1723,\n",
       "  None,\n",
       "  'This recipe needs adjustment, for example:\\n\\n*it was waaayyyyyy toooo sweet\\n*it got burnt \\n*the middle part is the only edible part \\n\\n\\nHow to fix it?:\\n\\n-use 1/4 cup of sugar instead of 1/2 \\n- bake for 9-12 minutes at *maximum*\\n-try using something like a spoon (if you dont have an icecream scoop), to divide the dough to equal/perfectly shaped cookies, so that they cook evenly. \\n\\n\\nOther than that, this was a really good recipe, a nice day! 💓',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgynHTik7JNIBbrJdUV4AaABAg.8mnh3HZCKS68xk5EF3hkij',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCSbWTOk3Ct2BP43h3EKePnA',\n",
       "  '2019-07-23 21:42:19+00:00',\n",
       "  0,\n",
       "  'UgynHTik7JNIBbrJdUV4AaABAg',\n",
       "  'Oh weird it turned out fine for me',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgynHTik7JNIBbrJdUV4AaABAg.8mnh3HZCKS68xVgYW_eL7r',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UC_t12dqFVBLkim3i5E__K4g',\n",
       "  '2019-07-17 22:09:17+00:00',\n",
       "  0,\n",
       "  'UgynHTik7JNIBbrJdUV4AaABAg',\n",
       "  'I agree... the dough was too wet..',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgynHTik7JNIBbrJdUV4AaABAg.8mnh3HZCKS68xPddfwXEnt',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCotCLMM5mauoaahJ0LqYB2g',\n",
       "  '2019-07-15 13:48:28+00:00',\n",
       "  0,\n",
       "  'UgynHTik7JNIBbrJdUV4AaABAg',\n",
       "  'i love you juice you should check your sugar to salt ratio, the sugar ratio must be more than the salt at all times, salt is just to enhance the flavors (a small amount always does the trick), but don’t overdo salt.',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgynHTik7JNIBbrJdUV4AaABAg.8mnh3HZCKS68xPdaVyYNxA',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCotCLMM5mauoaahJ0LqYB2g',\n",
       "  '2019-07-15 13:48:02+00:00',\n",
       "  0,\n",
       "  'UgynHTik7JNIBbrJdUV4AaABAg',\n",
       "  'Rose - Roblox you should check your sugar to salt ratio, the sugar ratio must be more than the salt at all times, salt is just to enhance the flavors (a small amount always does the trick), but don’t overdo salt.',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgynHTik7JNIBbrJdUV4AaABAg.8mnh3HZCKS68xPdL3b6V7i',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCotCLMM5mauoaahJ0LqYB2g',\n",
       "  '2019-07-15 13:45:47+00:00',\n",
       "  0,\n",
       "  'UgynHTik7JNIBbrJdUV4AaABAg',\n",
       "  'nicole p thank youuu!',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgzxBQnHjcADnS3PAL14AaABAg',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UC08yWPDdeAqks_Fxj285y1w',\n",
       "  '2018-09-05 21:13:16+00:00',\n",
       "  481,\n",
       "  None,\n",
       "  \"Hello! I made this recipe and for anyone looking for suggestions,  I recommend making these adjustments.\\n-1/4 cup of sugar instead of 1/2 cup\\n-Only 1/2 tsp of salt\\n-Do small balls, they expand A LOT\\n-Only bake for 10-12 minutes\\n\\nAlso if you're making a double batch, use a bit more flour.\",\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgzxBQnHjcADnS3PAL14AaABAg.8kpUjfIMs2P8xr0WFycTVl',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCFRq1QfJlu0LdxNidSK7gZw',\n",
       "  '2019-07-26 14:15:46+00:00',\n",
       "  1,\n",
       "  'UgzxBQnHjcADnS3PAL14AaABAg',\n",
       "  'Thank you so much ...I followed the recipe and changed the quantity of sugar with what you suggested.. And they taste like heaven 😍',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgzxBQnHjcADnS3PAL14AaABAg.8kpUjfIMs2P8xfM_XI_8Il',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCgyqEXHyZICyXW-ok3dpv1w',\n",
       "  '2019-07-22 01:37:42+00:00',\n",
       "  0,\n",
       "  'UgzxBQnHjcADnS3PAL14AaABAg',\n",
       "  'The temperature of the oven should be at 325 not 350',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgzxBQnHjcADnS3PAL14AaABAg.8kpUjfIMs2P8xePvrdPVbn',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCclsQtgkBsiYEqlIedITpvg',\n",
       "  '2019-07-21 16:47:43+00:00',\n",
       "  0,\n",
       "  'UgzxBQnHjcADnS3PAL14AaABAg',\n",
       "  \"hello, i don't know if you remember, but how many cookies  came out?\",\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgzxBQnHjcADnS3PAL14AaABAg.8kpUjfIMs2P8xKmT2TkoOP',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCgTTe_NxTuIXDeXoDJBsE_A',\n",
       "  '2019-07-13 16:29:19+00:00',\n",
       "  0,\n",
       "  'UgzxBQnHjcADnS3PAL14AaABAg',\n",
       "  'Can we add milk? I tried many time, but it always turned out to be muffins😢',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None),\n",
       " ('UgzxBQnHjcADnS3PAL14AaABAg.8kpUjfIMs2P8x7qWTdEWns',\n",
       "  '3vUtRRZG0xY',\n",
       "  'UCSHQYhDWQSFctChA1i9HBWw',\n",
       "  '2019-07-08 15:54:37+00:00',\n",
       "  0,\n",
       "  'UgzxBQnHjcADnS3PAL14AaABAg',\n",
       "  'OMG yess they expand so much 😂😂 mine have turned into a big square but yet taste delicious',\n",
       "  'en',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"SELECT * FROM comments WHERE publishedAt > 2018 anD videoId = '3vUtRRZG0xY'\" \n",
    "db.query(sql)\n",
    "tmp = db.cursor.fetchall()\n",
    "len(tmp)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 17)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get_comments_df(\n",
    "    video_search='chocolate, cream'\n",
    ").shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
